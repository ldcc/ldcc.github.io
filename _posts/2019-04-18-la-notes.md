---
layout: post
title: Learning notes of Linear Algebra
category: MATHEMATICS
date: 2019-04-18
---

Linear algebra is a tool of mathematics that is widely used throughout science and engineering.
Yet because linear algebra is a form of continuous rather than discrete mathematics,
many computer scientists have inexperience with it.

{% include brline %}

$$
\DeclareMathOperator{infer}{\Gamma \vdash}
\newcommand{norm}[1]{\|#1\|}
\newcommand{v}[1]{\mathbf{\vec{#1}}}
\newcommand{u}[1]{\mathbf{\hat{#1}}}
\newcommand{t}[1]{\boldsymbol{#1}}
$$ Preliminary
{: .hide}

[Norm]: https://en.wikipedia.org/wiki/Norm_(mathematics)
[Scalar]: https://en.wikipedia.org/wiki/Scalar_(mathematics)

## Unit Vector

The normalized vector $$\u{u}$$ of a non-zero vector $$\v{u}$$ is the unit vector in the direction of vector $$\v{u}$$,

### Proof: 

$$
\sigma ::= \mathbb{R}^n \mid \begin{bmatrix} a_1 \\ \vdots \\ a_n \end{bmatrix},
\qquad \u{u} \in \sigma, \qquad \norm{\u{u}} = 1  
$$$$$$

where $$\sigma$$ is the type of vector, $$\u{u}$$ means Unit-Vector, $$\norm{\v{u}}$$ is the [Norm][Norm] that is the magnitude of vector,

$$
\frac{\infer \u{u} : \sigma}
     {\infer k\norm{\u{u}} \equiv k}
$$

$$\Gamma$$ is the context we care about on algebra, and by the way as we know $$\u{u}$$ is a vector, surely $$k\u{u}$$ also is a vector,

$$
\frac{\infer k\norm{\u{u} : \sigma} \equiv k \quad \infer \v{u} : \sigma}
     {\infer \norm{\v{u}} \equiv k}
\qquad \v{u} := k\u{u}
$$

By two step, we got $$\infer \left(k\norm{\u{u}} \equiv k\right) \wedge \left(\norm{\v{u}} \equiv k\right)$$.

Due to $$\u{u} = \frac{k\u{u}}{k}$$, and thence as we can attempt to do some substitute for this:

$$
\frac{\infer k\norm{\u{u} : \sigma} \equiv \norm{\v{u} : \sigma}}
     {\infer \u{u} \equiv \frac{\v{u}}{k\norm{\u{u}}} \equiv \frac{\v{u}}{\norm{\v{u}}}}
$$

Normally denote as: $$\u{u} \equiv \frac{\v{u}}{\norm{\v{u}}}$$.

Apparently, $$\norm{\v{u}}$$ is a [Scalar][Scalar], and apparently so, $$\u{u}$$ is the unit vector in the direction of non-zero vector $$\v{u}$$.

{% include brline %}

## Dot Product

在计算点积时，被乘数和乘数分别代表着不同的数学意义，前者代表了整个线性方程组中的常数，后者代表了同一组线性方程中的所有变元。

{% include brline %}

## Linear Equations

Write down a system of linear equations: 

$$
\t{Ax} = \t{b}
$$

$$\t{A}$$ 代表了方程组中的常数，$$\t{x}$$ 代表了方程组中的变元，另一侧的 $$\t{b}$$ 是各组常数与变元之间的线性组合，是该线性方程组的解。

For this equation $$\t{Ax} = \t{b}$$, it is possible to have exactly one solution for every value of $$\t{b}$$. \\
And it is also possible to have no solutions or in infinitely many solutions for some values of $$\t{b}$$. \\
But it is not possible to have more than one but less than infinitely many solutions for a particular $$\t{b}$$.

{% include brline %}

## Transpose

One important operation on matrices is the transpose, the transpose of a matrix is the mirror image of the matrix across a diagonal line.

$$
\big( \t{A}^\top \big)_{i,j}= \t{A}_{j,i}
$$

The transpose of a matrix product has a simple form:

$$
\big( \t{AB} \big)^\top = \t{B}^\top \t{A}^\top
$$

{% include brline %}

## Identity Matrices (Unit-Matrices)

An identity matrix is a matrix that does not change any vector when we multiply that vector by that matrix.

$$
\forall x \in \mathbb{R}^n . \left( \t{I}_n \t{x} = x \right), \qquad \t{I}_n \in \mathbb{R}^{n×n}
$$

$$
\t{I}_1 = \begin{bmatrix} 
            1 
          \end{bmatrix}, 
\t{I}_2 = \begin{bmatrix} 
            1 & 0 \\
            0 & 1 \\
          \end{bmatrix},
\t{I}_3 = \begin{bmatrix}
            1 & 0 & 0 \\
            0 & 1 & 0 \\
            0 & 0 & 1 \\
          \end{bmatrix},
\dots,
\t{I}_n = \begin{bmatrix}
            1      & 0      & 0      & \dots  & 0      \\
            0      & 1      & 0      & \dots  & 0      \\
            0      & 0      & 1      & \dots  & 0      \\
            \vdots & \vdots & \vdots & \ddots & \vdots \\
            0      & 0      & 0      & \dots  & 1      \\
          \end{bmatrix}
$$

{% include brline %}

## Inverse Matrices

The matrix inverse of $$\t{A}$$ is denoted as $$\t{A}^{−1}$$, and it is deﬁned as the matrix such that:

$$
\t{A}^{−1}\t{A} = \t{I}_n
$$

We can now solve the linear equation using the following steps:

$$
\begin{split}
\t{Ax}                 & = \t{b}            \\
\t{A}^{-1} \t{Ax} & = \t{A}^{-1} \t{b} \\
\t{I}_n \t{x}          & = \t{A}^{-1} \t{b} \\
\t{x}                  & = \t{A}^{-1} \t{b} \\
\end{split}
$$

{% include brline %}

## Linear Combination

Think of the columns of $$\t{A}$$ purely as specifying different directions we can travel in from the origin.

列向量的意义并非为了描述出一个解，而是为了描述出列中各常量间的比值，即关于某个变元的方向。
在此观点下， $$\t{x}$$ 中的标量（即某个变元）就决定了各自在 $$\t{A}$$ 中所对应的列向量所表示的方向上能走多远。

当得到了一个具体的 $$\t{x}$$ 时，将 $$\t{A}$$ 的列向量乘以对应标量系数再加在一起便能得到该线性方程组一个具体的解：

$$
\t{Ax} = \sum_{i} x_i \t{A}_{:,i}
$$

In general, this kind of operation is called a linear combination:

$$
\sum_{i} c_i \t{v}^{(i)}
$$

{% include brline %}

## Span(Generating Subspace)

A set of vectors can be obtain a solution of a point or vector by linear combination with a particular $$\t{x}$$.

Similarly, a set of directions can be obtain a solution of space by linear combination with an arbitrary $$\t{x}$$.

And general, this kind of space is called a span.

The span of a set of vectors is the set of all points obtainable by linear combination of those vectors.

{% include brline %}

## Column Space (Range)

In linear algebra, the column space of a matrix $$\t{A}$$ exactly is the span of it's column vectors of $$\t{A}$$.

确定 $$\t{Ax} = \t{b} $$ 是否有解相当于确定向量 $$\t{b}$$ 是否在 $$\t{A}$$ 的列向量的生成子空间中。 

{% include brline %}

## Linear Dependence

在讨论线性组合时，矩阵 $$\t{A}$$ 的列向量通常被描述成一个方向，那么当 $$\t{A}$$ 中出现两个方向完全相同的列向量时，它们的线性组合又如何呢？
在一个方向上走了一段路后再往同一个方向上继续走，所走过的空间毫无疑问是一条直线。

如果一组向量中某些向量的线性组合可以表示成另一个向量，那么这个向量对这组向量而言便是冗余的，因为这个向量不会增加这组向量的生成子空间。

正式地说，这种冗余被称为线性相关；相反的，如果一组向量的任意向量进行线性组合都不能表示成其他向量时，这组向量称为线性无关。

{% include brline %}

## Norm

Formally, the $$L^p$$ normis given by:

$$
\norm{\t{x}}_p = \left( \sum_i |x_i|^p \right)^{\frac{1}{p}},
\qquad \ p \in \mathbb{R}, \ p \ge 1
$$




(?<=[a-zA-Z])\} ?+\\t\{
{:.hide}